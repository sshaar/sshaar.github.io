---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'That is a Known Lie: Detecting Previously Fact-Checked Claims'
subtitle: ''
summary: ''
authors:
- Shaden Shaar
- Nikolay Babulkov
- Giovanni Da San Martino
- Preslav Nakov
tags: []
categories: []
date: '2020-07-01'
lastmod: 2023-03-27T23:52:26-04:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2023-03-28T03:52:26.848565Z'
publication_types:
- '1'
abstract: The recent proliferation of ″fake news″ has triggered a number of responses,
  most notably the emergence of several manual fact-checking initiatives. As a result
  and over time, a large number of fact-checked claims have been accumulated, which
  increases the likelihood that a new claim in social media or a new statement by
  a politician might have already been fact-checked by some trusted fact-checking
  organization, as viral claims often come back after a while in social media, and
  politicians like to repeat their favorite statements, true or false, over and over
  again. As manual fact-checking is very time-consuming (and fully automatic fact-checking
  has credibility issues), it is important to try to save this effort and to avoid
  wasting time on claims that have already been fact-checked. Interestingly, despite
  the importance of the task, it has been largely ignored by the research community
  so far. Here, we aim to bridge this gap. In particular, we formulate the task and
  we discuss how it relates to, but also differs from, previous work. We further create
  a specialized dataset, which we release to the research community. Finally, we present
  learning-to-rank experiments that demonstrate sizable improvements over state-of-the-art
  retrieval and textual similarity approaches.
publication: '*Proceedings of the 58th Annual Meeting of the Association for Computational
  Linguistics*'
doi: 10.18653/v1/2020.acl-main.332
links:
- name: URL
  url: https://aclanthology.org/2020.acl-main.332
---
